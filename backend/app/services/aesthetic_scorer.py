# -*- coding: utf-8 -*-
"""
AIç¾å­¦è¯„åˆ†æœåŠ¡
ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¯„ä¼°å›¾åƒç¾å­¦è´¨é‡
"""
import os
from typing import Optional, Dict
import numpy as np

# å…¨å±€å˜é‡ï¼Œå»¶è¿ŸåŠ è½½æ¨¡å‹
_model = None
_transform = None
_device = None
_model_loaded = False
_load_attempted = False


def _load_model():
    """å»¶è¿ŸåŠ è½½æ¨¡å‹ï¼ˆé¦–æ¬¡ä½¿ç”¨æ—¶ï¼‰"""
    global _model, _transform, _device, _model_loaded, _load_attempted
    
    if _load_attempted:
        return _model_loaded
    
    _load_attempted = True
    
    try:
        import torch
        import torchvision.transforms as transforms
        import torchvision.models as models
        
        print("ğŸ”„ æ­£åœ¨åŠ è½½AIç¾å­¦è¯„åˆ†æ¨¡å‹...")
        
        # ä½¿ç”¨CPU
        _device = torch.device("cpu")
        
        # åŠ è½½é¢„è®­ç»ƒçš„ MobileNetV2ï¼ˆè½»é‡çº§ï¼ŒCPUå‹å¥½ï¼‰
        _model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)
        _model.eval()
        _model.to(_device)
        
        # å›¾åƒé¢„å¤„ç†
        _transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])
        
        _model_loaded = True
        print("âœ… AIç¾å­¦è¯„åˆ†æ¨¡å‹åŠ è½½å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"[WARN] AIç¾å­¦æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        _model_loaded = False
        return False


def analyze_aesthetic(image_path: str) -> Dict:
    """
    åˆ†æå›¾åƒç¾å­¦è´¨é‡
    
    è¿”å›:
        {
            "aesthetic_score": 0-100,  # ç¾å­¦è¯„åˆ†
            "composition_score": 0-100,  # æ„å›¾è¯„åˆ†
            "color_harmony": 0-100,  # è‰²å½©å’Œè°åº¦
            "clarity_score": 0-100,  # æ¸…æ™°åº¦è¯„åˆ†
            "feature_richness": 0-100,  # ç‰¹å¾ä¸°å¯Œåº¦
        }
    """
    result = {
        "aesthetic_score": 50,
        "composition_score": 50,
        "color_harmony": 50,
        "clarity_score": 50,
        "feature_richness": 50,
    }
    
    try:
        import cv2
        
        # è¯»å–å›¾åƒ
        img = cv2.imread(image_path)
        if img is None:
            return result
        
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # 1. åŸºç¡€å›¾åƒåˆ†æï¼ˆOpenCVï¼‰
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        
        # æ¸…æ™°åº¦ï¼ˆLaplacianæ–¹å·®ï¼‰
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        clarity_score = min(100, laplacian_var / 5)  # å½’ä¸€åŒ–åˆ°0-100
        
        # è‰²å½©å’Œè°åº¦ï¼ˆé¢œè‰²åˆ†å¸ƒçš„å‡åŒ€æ€§ï¼‰
        h_std = np.std(hsv[:, :, 0])
        s_mean = np.mean(hsv[:, :, 1])
        color_harmony = min(100, (h_std * 0.5 + s_mean * 0.3))
        
        # 2. æ„å›¾åˆ†æ
        composition_score = _analyze_composition(img)
        
        # 3. AIç‰¹å¾åˆ†æï¼ˆå¦‚æœæ¨¡å‹å¯ç”¨ï¼‰
        feature_richness = 50
        ai_aesthetic = 50
        
        if _load_model():
            try:
                import torch
                
                # æå–ç‰¹å¾
                input_tensor = _transform(img_rgb).unsqueeze(0).to(_device)
                
                with torch.no_grad():
                    features = _model.features(input_tensor)
                    # ç‰¹å¾ä¸°å¯Œåº¦ï¼ˆç‰¹å¾æ¿€æ´»çš„å¤šæ ·æ€§ï¼‰
                    feature_std = features.std().item()
                    feature_mean = features.mean().item()
                    feature_richness = min(100, (feature_std * 100 + abs(feature_mean) * 20))
                    
                    # åŸºäºç‰¹å¾çš„ç¾å­¦è¯„åˆ†
                    # é«˜å±‚ç‰¹å¾çš„æ¿€æ´»å¼ºåº¦ä¸ç¾å­¦ç›¸å…³
                    pooled = torch.nn.functional.adaptive_avg_pool2d(features, 1)
                    top_activations = torch.topk(pooled.flatten(), k=50).values.mean().item()
                    ai_aesthetic = min(100, top_activations * 15)
                    
            except Exception as e:
                print(f"AIç‰¹å¾æå–å¤±è´¥: {e}")
        
        # 4. ç»¼åˆç¾å­¦è¯„åˆ†
        aesthetic_score = (
            clarity_score * 0.25 +      # æ¸…æ™°åº¦ 25%
            color_harmony * 0.20 +      # è‰²å½© 20%
            composition_score * 0.25 +   # æ„å›¾ 25%
            feature_richness * 0.15 +    # ç‰¹å¾ä¸°å¯Œåº¦ 15%
            ai_aesthetic * 0.15          # AIè¯„åˆ† 15%
        )
        
        result = {
            "aesthetic_score": round(aesthetic_score, 1),
            "composition_score": round(composition_score, 1),
            "color_harmony": round(color_harmony, 1),
            "clarity_score": round(clarity_score, 1),
            "feature_richness": round(feature_richness, 1),
        }
        
    except Exception as e:
        print(f"ç¾å­¦åˆ†æå¤±è´¥: {e}")
    
    return result


def _analyze_composition(img) -> float:
    """
    åˆ†æå›¾åƒæ„å›¾è´¨é‡
    åŸºäºä¸‰åˆ†æ³•åˆ™å’Œé»„é‡‘åˆ†å‰²
    """
    try:
        import cv2
        
        h, w = img.shape[:2]
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # æ£€æµ‹è¾¹ç¼˜
        edges = cv2.Canny(gray, 50, 150)
        
        # ä¸‰åˆ†æ³•åˆ™åŒºåŸŸï¼ˆå…³é”®ç‚¹ä½ç½®ï¼‰
        thirds_x = [w // 3, 2 * w // 3]
        thirds_y = [h // 3, 2 * h // 3]
        
        # è®¡ç®—å…³é”®åŒºåŸŸçš„è¾¹ç¼˜å¯†åº¦
        roi_scores = []
        roi_size = min(w, h) // 6
        
        for x in thirds_x:
            for y in thirds_y:
                x1 = max(0, x - roi_size)
                x2 = min(w, x + roi_size)
                y1 = max(0, y - roi_size)
                y2 = min(h, y + roi_size)
                
                roi = edges[y1:y2, x1:x2]
                density = np.sum(roi > 0) / roi.size if roi.size > 0 else 0
                roi_scores.append(density)
        
        # ä¸­å¿ƒåŒºåŸŸçš„é‡è¦æ€§
        center_x, center_y = w // 2, h // 2
        center_roi = edges[
            center_y - roi_size:center_y + roi_size,
            center_x - roi_size:center_x + roi_size
        ]
        center_density = np.sum(center_roi > 0) / center_roi.size if center_roi.size > 0 else 0
        
        # æ„å›¾è¯„åˆ†ï¼šä¸‰åˆ†ç‚¹æœ‰å†…å®¹ + ä¸­å¿ƒé€‚åº¦
        thirds_score = np.mean(roi_scores) * 200
        center_score = min(50, center_density * 100)  # ä¸­å¿ƒä¸èƒ½å¤ªæ»¡
        
        composition = min(100, thirds_score + center_score)
        
        return composition
        
    except Exception as e:
        return 50


def get_best_frame(frame_paths: list) -> tuple:
    """
    ä»å¤šä¸ªå€™é€‰å¸§ä¸­é€‰æ‹©ç¾å­¦è¯„åˆ†æœ€é«˜çš„
    
    Args:
        frame_paths: å€™é€‰å¸§å›¾ç‰‡è·¯å¾„åˆ—è¡¨
    
    Returns:
        (æœ€ä½³å¸§è·¯å¾„, è¯„åˆ†è¯¦æƒ…)
    """
    best_path = frame_paths[0] if frame_paths else None
    best_score = 0
    best_analysis = {}
    
    for path in frame_paths:
        analysis = analyze_aesthetic(path)
        score = analysis.get("aesthetic_score", 0)
        
        if score > best_score:
            best_score = score
            best_path = path
            best_analysis = analysis
    
    return best_path, best_analysis




# -*- coding: utf-8 -*-
"""
AIç¾å­¦è¯„åˆ†æœåŠ¡
ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¯„ä¼°å›¾åƒç¾å­¦è´¨é‡
"""
import os
from typing import Optional, Dict
import numpy as np

# å…¨å±€å˜é‡ï¼Œå»¶è¿ŸåŠ è½½æ¨¡å‹
_model = None
_transform = None
_device = None
_model_loaded = False
_load_attempted = False


def _load_model():
    """å»¶è¿ŸåŠ è½½æ¨¡å‹ï¼ˆé¦–æ¬¡ä½¿ç”¨æ—¶ï¼‰"""
    global _model, _transform, _device, _model_loaded, _load_attempted
    
    if _load_attempted:
        return _model_loaded
    
    _load_attempted = True
    
    try:
        import torch
        import torchvision.transforms as transforms
        import torchvision.models as models
        
        print("ğŸ”„ æ­£åœ¨åŠ è½½AIç¾å­¦è¯„åˆ†æ¨¡å‹...")
        
        # ä½¿ç”¨CPU
        _device = torch.device("cpu")
        
        # åŠ è½½é¢„è®­ç»ƒçš„ MobileNetV2ï¼ˆè½»é‡çº§ï¼ŒCPUå‹å¥½ï¼‰
        _model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)
        _model.eval()
        _model.to(_device)
        
        # å›¾åƒé¢„å¤„ç†
        _transform = transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])
        
        _model_loaded = True
        print("âœ… AIç¾å­¦è¯„åˆ†æ¨¡å‹åŠ è½½å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âš ï¸ AIç¾å­¦æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        _model_loaded = False
        return False


def analyze_aesthetic(image_path: str) -> Dict:
    """
    åˆ†æå›¾åƒç¾å­¦è´¨é‡
    
    è¿”å›:
        {
            "aesthetic_score": 0-100,  # ç¾å­¦è¯„åˆ†
            "composition_score": 0-100,  # æ„å›¾è¯„åˆ†
            "color_harmony": 0-100,  # è‰²å½©å’Œè°åº¦
            "clarity_score": 0-100,  # æ¸…æ™°åº¦è¯„åˆ†
            "feature_richness": 0-100,  # ç‰¹å¾ä¸°å¯Œåº¦
        }
    """
    result = {
        "aesthetic_score": 50,
        "composition_score": 50,
        "color_harmony": 50,
        "clarity_score": 50,
        "feature_richness": 50,
    }
    
    try:
        import cv2
        
        # è¯»å–å›¾åƒ
        img = cv2.imread(image_path)
        if img is None:
            return result
        
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # 1. åŸºç¡€å›¾åƒåˆ†æï¼ˆOpenCVï¼‰
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        
        # æ¸…æ™°åº¦ï¼ˆLaplacianæ–¹å·®ï¼‰
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        clarity_score = min(100, laplacian_var / 5)  # å½’ä¸€åŒ–åˆ°0-100
        
        # è‰²å½©å’Œè°åº¦ï¼ˆé¢œè‰²åˆ†å¸ƒçš„å‡åŒ€æ€§ï¼‰
        h_std = np.std(hsv[:, :, 0])
        s_mean = np.mean(hsv[:, :, 1])
        color_harmony = min(100, (h_std * 0.5 + s_mean * 0.3))
        
        # 2. æ„å›¾åˆ†æ
        composition_score = _analyze_composition(img)
        
        # 3. AIç‰¹å¾åˆ†æï¼ˆå¦‚æœæ¨¡å‹å¯ç”¨ï¼‰
        feature_richness = 50
        ai_aesthetic = 50
        
        if _load_model():
            try:
                import torch
                
                # æå–ç‰¹å¾
                input_tensor = _transform(img_rgb).unsqueeze(0).to(_device)
                
                with torch.no_grad():
                    features = _model.features(input_tensor)
                    # ç‰¹å¾ä¸°å¯Œåº¦ï¼ˆç‰¹å¾æ¿€æ´»çš„å¤šæ ·æ€§ï¼‰
                    feature_std = features.std().item()
                    feature_mean = features.mean().item()
                    feature_richness = min(100, (feature_std * 100 + abs(feature_mean) * 20))
                    
                    # åŸºäºç‰¹å¾çš„ç¾å­¦è¯„åˆ†
                    # é«˜å±‚ç‰¹å¾çš„æ¿€æ´»å¼ºåº¦ä¸ç¾å­¦ç›¸å…³
                    pooled = torch.nn.functional.adaptive_avg_pool2d(features, 1)
                    top_activations = torch.topk(pooled.flatten(), k=50).values.mean().item()
                    ai_aesthetic = min(100, top_activations * 15)
                    
            except Exception as e:
                print(f"AIç‰¹å¾æå–å¤±è´¥: {e}")
        
        # 4. ç»¼åˆç¾å­¦è¯„åˆ†
        aesthetic_score = (
            clarity_score * 0.25 +      # æ¸…æ™°åº¦ 25%
            color_harmony * 0.20 +      # è‰²å½© 20%
            composition_score * 0.25 +   # æ„å›¾ 25%
            feature_richness * 0.15 +    # ç‰¹å¾ä¸°å¯Œåº¦ 15%
            ai_aesthetic * 0.15          # AIè¯„åˆ† 15%
        )
        
        result = {
            "aesthetic_score": round(aesthetic_score, 1),
            "composition_score": round(composition_score, 1),
            "color_harmony": round(color_harmony, 1),
            "clarity_score": round(clarity_score, 1),
            "feature_richness": round(feature_richness, 1),
        }
        
    except Exception as e:
        print(f"ç¾å­¦åˆ†æå¤±è´¥: {e}")
    
    return result


def _analyze_composition(img) -> float:
    """
    åˆ†æå›¾åƒæ„å›¾è´¨é‡
    åŸºäºä¸‰åˆ†æ³•åˆ™å’Œé»„é‡‘åˆ†å‰²
    """
    try:
        import cv2
        
        h, w = img.shape[:2]
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # æ£€æµ‹è¾¹ç¼˜
        edges = cv2.Canny(gray, 50, 150)
        
        # ä¸‰åˆ†æ³•åˆ™åŒºåŸŸï¼ˆå…³é”®ç‚¹ä½ç½®ï¼‰
        thirds_x = [w // 3, 2 * w // 3]
        thirds_y = [h // 3, 2 * h // 3]
        
        # è®¡ç®—å…³é”®åŒºåŸŸçš„è¾¹ç¼˜å¯†åº¦
        roi_scores = []
        roi_size = min(w, h) // 6
        
        for x in thirds_x:
            for y in thirds_y:
                x1 = max(0, x - roi_size)
                x2 = min(w, x + roi_size)
                y1 = max(0, y - roi_size)
                y2 = min(h, y + roi_size)
                
                roi = edges[y1:y2, x1:x2]
                density = np.sum(roi > 0) / roi.size if roi.size > 0 else 0
                roi_scores.append(density)
        
        # ä¸­å¿ƒåŒºåŸŸçš„é‡è¦æ€§
        center_x, center_y = w // 2, h // 2
        center_roi = edges[
            center_y - roi_size:center_y + roi_size,
            center_x - roi_size:center_x + roi_size
        ]
        center_density = np.sum(center_roi > 0) / center_roi.size if center_roi.size > 0 else 0
        
        # æ„å›¾è¯„åˆ†ï¼šä¸‰åˆ†ç‚¹æœ‰å†…å®¹ + ä¸­å¿ƒé€‚åº¦
        thirds_score = np.mean(roi_scores) * 200
        center_score = min(50, center_density * 100)  # ä¸­å¿ƒä¸èƒ½å¤ªæ»¡
        
        composition = min(100, thirds_score + center_score)
        
        return composition
        
    except Exception as e:
        return 50


def get_best_frame(frame_paths: list) -> tuple:
    """
    ä»å¤šä¸ªå€™é€‰å¸§ä¸­é€‰æ‹©ç¾å­¦è¯„åˆ†æœ€é«˜çš„
    
    Args:
        frame_paths: å€™é€‰å¸§å›¾ç‰‡è·¯å¾„åˆ—è¡¨
    
    Returns:
        (æœ€ä½³å¸§è·¯å¾„, è¯„åˆ†è¯¦æƒ…)
    """
    best_path = frame_paths[0] if frame_paths else None
    best_score = 0
    best_analysis = {}
    
    for path in frame_paths:
        analysis = analyze_aesthetic(path)
        score = analysis.get("aesthetic_score", 0)
        
        if score > best_score:
            best_score = score
            best_path = path
            best_analysis = analysis
    
    return best_path, best_analysis


